# Production-RAG-System-with-Qwen-LangGraph-Redis
Production-ready RAG system built with Qwen, LangGraph, FAISS, and Redis. Supports hybrid search, reranking, streaming responses, and session-based memory via FastAPI. Demonstrates scalable AI backend architecture for document Q&amp;A and enterprise assistants.

# ğŸ§  Production RAG System with Qwen + LangGraph + Redis

A production-ready Retrieval-Augmented Generation (RAG) system built using:

- Qwen LLM (HuggingFace endpoint)
- LangGraph agent workflow
- Hybrid search (FAISS + BM25)
- Reranking
- Streaming responses
- Redis caching + memory
- FastAPI backend

This project demonstrates how to build a real-world AI backend similar to enterprise document assistants.

---

## ğŸš€ Features

### ğŸ” Retrieval
- FAISS vector search
- BM25 keyword search
- Hybrid retrieval
- Cross-encoder reranking

### ğŸ§  LLM
- Qwen2-7B-Instruct via HuggingFace
- Optimized prompts
- Streaming responses

### ğŸ•¸ LangGraph Agent
- Query rewriting node
- Retrieval node
- Generation node
- Extensible graph workflow

### ğŸ’¾ Redis Backend
- Persistent conversation memory
- Response caching
- Multi-session support

### ğŸŒ API
- FastAPI server
- Streaming endpoint
- Session-based chat

---

## ğŸ— Architecture
User
â†“
FastAPI
â†“
LangGraph Agent
â”œâ”€ Query Rewrite
â”œâ”€ Hybrid Retrieval
â”œâ”€ Reranker
â””â”€ LLM Generation
â†“
Redis
â”œâ”€ Cache
â””â”€ Memory
